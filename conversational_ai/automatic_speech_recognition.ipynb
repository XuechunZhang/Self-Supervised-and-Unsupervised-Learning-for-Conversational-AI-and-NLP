{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/Users/chandra/anaconda3/lib/python3.7/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:419: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AND WILL BE HEARD ORDER ORDER THE ORABLE GENTLEMAN HAS GOT TO LEARN THE ART OF PATIENCE AND IF HE IS PATIENT']\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC\n",
    "import librosa as lb\n",
    "import torch\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "\n",
    "# Initialize the model\n",
    "model = Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "\n",
    "# Read the sound file\n",
    "waveform, rate = lb.load('./sample_audio_files/sample_speech_file.wav', sr = 16000)\n",
    "\n",
    "# Tokenize the waveform\n",
    "input_values = tokenizer(waveform, return_tensors='pt').input_values\n",
    "\n",
    "# Retrieve logits from the model\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# Take argmax value and decode into transcription\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = tokenizer.batch_decode(predicted_ids)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset librispeech_asr (/Users/chandra/.cache/huggingface/datasets/librispeech_asr/clean/2.1.0/468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1)\n",
      "Loading cached processed dataset at /Users/chandra/.cache/huggingface/datasets/librispeech_asr/clean/2.1.0/468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1/cache-83ab6027297f59f2.arrow\n",
      "/Users/chandra/anaconda3/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man said to the universe sir i exist']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "inputs = processor(ds[\"speech\"][0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "generated_ids = model.generate(input_ids=inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids)\n",
    "\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be64804f73e37741e32e8ef3a551b06a02113c01da7b83268c03fb56d3fe9a06"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
